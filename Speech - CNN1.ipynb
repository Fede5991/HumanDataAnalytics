{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech- CNN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import winsound\n",
    "import time\n",
    "\n",
    "from IAHOS import IAHOS\n",
    "from extraction_performances import extraction_performances\n",
    "from hyperparams_initialization import hyperparams_initialization\n",
    "from plots import plot_IAHOS,plot_confusion_matrix\n",
    "from plots import plot_training_accuracy,plot_validation_accuracy,plot_test_scores\n",
    "from plots import plot_output_NN\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Conv2D,Conv1D,MaxPooling2D,AveragePooling1D,MaxPooling1D\n",
    "from keras.layers import Dense,Flatten,Dropout\n",
    "from keras import initializers,optimizers,backend as k\n",
    "from keras_radam import RAdam\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=np.load('training_set.npy')\n",
    "validation_set=np.load('validation_set.npy')\n",
    "training_labels=np.load('training_labels.npy')\n",
    "validation_labels=np.load('validation_labels.npy')\n",
    "test_set=np.load('test_set.npy')\n",
    "test_labels=np.load('test_labels.npy')\n",
    "words_name=np.load('words_name.npy')\n",
    "randomize = np.arange(len(training_set))\n",
    "np.random.shuffle(randomize)\n",
    "training_set = training_set[randomize]\n",
    "training_labels = training_labels[randomize]\n",
    "randomize = np.arange(len(validation_set))\n",
    "np.random.shuffle(randomize)\n",
    "validation_set = validation_set[randomize]\n",
    "validation_labels = validation_labels[randomize]\n",
    "percentage = 10\n",
    "index1 = int(len(training_set)*percentage/100)\n",
    "index2 = int(len(validation_set)*percentage/100)\n",
    "training_set2 = training_set[0:index1].reshape((-1,40,98,1))\n",
    "validation_set2 = validation_set[0:index2].reshape((-1,40,98,1))\n",
    "training_set = training_set.reshape((-1,40,98,1))\n",
    "validation_set = validation_set.reshape((-1,40,98,1))\n",
    "training_labels2 = training_labels[0:index1]\n",
    "validation_labels2 = validation_labels[0:index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier(i,hm,optimizer,op):\n",
    "    x = Input(shape=(40,98,1))\n",
    "    x1 = (Conv2D(int(hm[0,i]),kernel_size=(40,int(hm[1,i])),activation='relu'))(x)\n",
    "    x1 = Dropout(rate=hm[8,i])(x1)\n",
    "    x1 = (MaxPooling2D(pool_size=(1,int(hm[2,i]))))(x1)\n",
    "    for j in range(int(hm[3,i])):\n",
    "        x1 = (Conv2D(int(hm[4,i]),kernel_size=(1,int(hm[5,i])),activation='relu'))(x1)\n",
    "        x1 = Dropout(rate=hm[8,i])(x1)\n",
    "        x1 = (MaxPooling2D(pool_size=(1,int(hm[6,i]))))(x1)\n",
    "    y1 = Flatten()(x1)\n",
    "    y2 = (Dense(int(hm[7,i]),activation='relu'))(y1)\n",
    "    y2 = Dropout(rate=hm[8,i])(y2)\n",
    "    y = (Dense(31,activation='softmax'))(y2)\n",
    "    classifier=Model(inputs=x,outputs=y)\n",
    "    if optimizer=='radam':\n",
    "        Optimizer=RAdam()\n",
    "    elif optimizer=='sgd':\n",
    "        if op[3]==0:\n",
    "            Optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "        else:\n",
    "            Optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=True)\n",
    "    elif optimizer=='rmsprop':\n",
    "        Optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    elif optimizer=='adagrad':\n",
    "        Optimizer=keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "    elif optimizer=='adadelta':\n",
    "        Optimizer=keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "    elif optimizer=='adam':\n",
    "        Optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    elif optimizer=='adamax':\n",
    "        Optimizer=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    else:\n",
    "        Optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    classifier.compile(optimizer=Optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts=2\n",
    "variables=9\n",
    "iterations=attempts**variables\n",
    "limits = [[4,64],[2,6],[1,2],[0,2],[2,64],[2,6],[1,2],[50,500],[0,0.5]]\n",
    "method='grid'\n",
    "rounds=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = [[],[0.01,0,0,0],[0.001,0.9,0,0],[0.01,0,0],[1,0.95,0,0],[0.001,0.9,0.999,0,0,0],\n",
    "      [0.002,0.9,0.999,0,0],[0.002,0.9,0.999,0,0.004]]\n",
    "tgp,tgp2,ogp,ogp2,final=IAHOS(rounds,method,limits,attempts,variables,iterations,Classifier,\n",
    "                       training_set,training_labels,validation_set,validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters studied for this neural network\n",
    "y = ['#filter1','kernel1','maxpool1','#layers',\n",
    "     '#filter2','kernel2','maxpool2','fully_dim','dropout']\n",
    "plot_IAHOS(y,ogp,ogp2,tgp,tgp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.reshape(-1,40,98,1)\n",
    "final = np.load('final.npy')\n",
    "best_hp = np.zeros((variables,1))\n",
    "for i in range(variables):\n",
    "    best_hp[i]=final[i]\n",
    "\n",
    "training_accuracy=[]\n",
    "validation_accuracy=[]\n",
    "test_scores=[]\n",
    "optimizers = ['radam','sgd','rmsprop','adagrad','adadelta','adam','adamax','nadam']\n",
    "\n",
    "epochs=30\n",
    "\n",
    "j=0\n",
    "for optimizer in tqdm(optimizers):\n",
    "        mc = ModelCheckpoint('best_model_'+optimizer+'.h5', monitor='val_loss', mode='min',\n",
    "                            verbose=0,save_best_only=True)\n",
    "        classifier=Classifier(0,best_hp,optimizer,op[j])\n",
    "        history=classifier.fit(training_set,training_labels,\n",
    "                               validation_data=[validation_set,validation_labels],\n",
    "                               epochs=epochs,batch_size=100,verbose=0,callbacks=[mc])\n",
    "        training_accuracy.append(history.history['acc'])\n",
    "        validation_accuracy.append(history.history['val_acc'])\n",
    "        j+=1\n",
    "        if j<7:\n",
    "            K.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
