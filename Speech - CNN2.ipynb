{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech - CNN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import winsound\n",
    "import time\n",
    "\n",
    "from IAHOS import IAHOS\n",
    "from extraction_performances import extraction_performances\n",
    "from hyperparams_initialization import hyperparams_initialization\n",
    "from plots import plot_IAHOS,plot_confusion_matrix\n",
    "from plots import plot_training_accuracy,plot_validation_accuracy,plot_test_scores\n",
    "from plots import plot_output_NN\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Conv2D,Conv1D,MaxPooling2D,AveragePooling1D,MaxPooling1D\n",
    "from keras.layers import Dense,Flatten,Dropout\n",
    "from keras import initializers,optimizers,backend as k\n",
    "from keras_radam import RAdam\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=np.load('training_set.npy')\n",
    "validation_set=np.load('validation_set.npy')\n",
    "training_labels=np.load('training_labels.npy')\n",
    "validation_labels=np.load('validation_labels.npy')\n",
    "test_set=np.load('test_set.npy')\n",
    "test_labels=np.load('test_labels.npy')\n",
    "words_name=np.load('words_name.npy')\n",
    "randomize = np.arange(len(training_set))\n",
    "np.random.shuffle(randomize)\n",
    "training_set = training_set[randomize]\n",
    "training_labels = training_labels[randomize]\n",
    "randomize = np.arange(len(validation_set))\n",
    "np.random.shuffle(randomize)\n",
    "validation_set = validation_set[randomize]\n",
    "validation_labels = validation_labels[randomize]\n",
    "percentage = 30\n",
    "index1 = int(len(training_set)*percentage/100)\n",
    "index2 = int(len(validation_set)*percentage/100)\n",
    "training_set2 = training_set[0:index1].reshape((-1,40,98,1))\n",
    "validation_set2 = validation_set[0:index2].reshape((-1,40,98,1))\n",
    "training_set = training_set.reshape((-1,40,98,1))\n",
    "validation_set = validation_set.reshape((-1,40,98,1))\n",
    "training_labels2 = training_labels[0:index1]\n",
    "validation_labels2 = validation_labels[0:index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier(i,hm,optimizer,op):\n",
    "    x = Input(shape=(40,98,1))\n",
    "    x1 = (Conv2D(int(hm[0,i]),kernel_size=(int(hm[1,i]),int(hm[2,i])),activation='relu'))(x)\n",
    "    x1 = Dropout(rate=hm[8,i])(x1)\n",
    "    x1 = (MaxPooling2D(pool_size=(int(hm[3,i]),int(hm[4,i]))))(x1)\n",
    "    x1 = (Conv2D(int(hm[5,i]),kernel_size=(int(hm[6,i]),int(hm[2,i])),activation='relu'))(x1)\n",
    "    x1 = Dropout(rate=hm[8,i])(x1)\n",
    "    x1 = (MaxPooling2D(pool_size=(int(hm[3,i]),int(hm[4,i]))))(x1)\n",
    "    y1 = Flatten()(x1)\n",
    "    y2 = (Dense(int(hm[7,i]),activation='relu'))(y1)\n",
    "    y2 = Dropout(rate=hm[8,i])(y2)\n",
    "    y = (Dense(31,activation='softmax'))(y2)\n",
    "    classifier=Model(inputs=x,outputs=y)\n",
    "    if optimizer=='radam':\n",
    "        Optimizer=RAdam()\n",
    "    elif optimizer=='sgd':\n",
    "        if op[3]==0:\n",
    "            Optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "        else:\n",
    "            Optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=True)\n",
    "    elif optimizer=='rmsprop':\n",
    "        Optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    elif optimizer=='adagrad':\n",
    "        Optimizer=keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "    elif optimizer=='adadelta':\n",
    "        Optimizer=keras.optimizers.Adadelta(lr=1.0, rho=0.95,epsilon=None, decay=0.0)\n",
    "    elif optimizer=='adam':\n",
    "        Optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    elif optimizer=='adamax':\n",
    "        Optimizer=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    else:\n",
    "        Optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    classifier.compile(optimizer=Optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts=2\n",
    "variables=9\n",
    "iterations=attempts**variables\n",
    "limits = [[4,64],[2,10],[2,20],[1,2],[1,3],[4,64],[2,4],[50,500],[0,0.5]]\n",
    "method='grid'\n",
    "rounds=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = [[],[0.01,0,0,0],[0.001,0.9,0,0],[0.01,0,0],[1,0.95,0,0],[0.001,0.9,0.999,0,0,0],\n",
    "      [0.002,0.9,0.999,0,0],[0.002,0.9,0.999,0,0.004]]\n",
    "tgp,tgp2,ogp,ogp2,final=IAHOS(rounds,method,limits,attempts,variables,iterations,Classifier,\n",
    "                       training_set,training_labels,validation_set,validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters studied for this neural network\n",
    "model = 'CNN2'\n",
    "y = ['#filter1','kernel1a','kernel1b','#maxpoola',\n",
    "     '#maxpoolb','filter2','kernel2a','fully_dim','dropout']\n",
    "plot_IAHOS(y,ogp,ogp2,tgp,tgp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.reshape(-1,40,98,1)\n",
    "final = np.load('final.npy')\n",
    "best_hp = np.zeros((variables,1))\n",
    "for i in range(variables):\n",
    "    best_hp[i]=final[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = [[],[0.01,0,0,0],[0.001,0.9,0,0],[0.01,0,0],[1,0.95,0,0],[0.001,0.9,0.999,0,0,0],\n",
    "      [0.002,0.9,0.999,0,0],[0.002,0.9,0.999,0,0.004]]\n",
    "training_accuracy=[]\n",
    "validation_accuracy=[]\n",
    "test_scores=[]\n",
    "optimizers = ['radam','sgd','rmsprop','adagrad','adadelta','adam','adamax','nadam']\n",
    "\n",
    "epochs=100\n",
    "j=0\n",
    "for optimizer in tqdm(optimizers):\n",
    "        mc = ModelCheckpoint('best_model_'+optimizer+'.h5', monitor='val_loss', mode='min',\n",
    "                            verbose=0,save_best_only=True)\n",
    "        classifier=Classifier(0,best_hp,optimizer,op[j])\n",
    "        history=classifier.fit(training_set,training_labels,\n",
    "                               validation_data=[validation_set,validation_labels],\n",
    "                               epochs=epochs,batch_size=512,verbose=0,callbacks=[mc])\n",
    "        training_accuracy.append(history.history['acc'])\n",
    "        validation_accuracy.append(history.history['val_acc'])\n",
    "        j+=1\n",
    "        if j<7:\n",
    "            K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = ['radam','sgd','rmsprop','adagrad','adadelta','adam','adamax','nadam']\n",
    "test_scores=[]\n",
    "j=0\n",
    "for optimizer in optimizers:\n",
    "    classifier=Classifier(0,best_hp,optimizer,op[j])\n",
    "    classifier.load_weights('best_model_'+str(optimizer)+'.h5')\n",
    "    predictions = classifier.predict(test_set)\n",
    "    new_test_labels = np.zeros(test_labels.shape[0])\n",
    "    for i in range(test_labels.shape[0]):\n",
    "        new_test_labels[i]=np.argmax(test_labels[i])\n",
    "    y_pred = np.zeros(test_labels.shape[0])\n",
    "    for i in range(test_labels.shape[0]):\n",
    "        y_pred[i]=np.argmax(predictions[i])\n",
    "    score=accuracy_score(y_true=new_test_labels,y_pred=y_pred, normalize=True)\n",
    "    test_scores.append(score)\n",
    "    j+=1\n",
    "    del classifier\n",
    "y = np.zeros((8,1))\n",
    "for i in range(8):\n",
    "    y[i,0]=test_scores[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='CNN2'\n",
    "scores=['test score accuracy']\n",
    "plot_training_accuracy(training_accuracy,optimizers,model)\n",
    "plot_validation_accuracy(validation_accuracy,optimizers,model)\n",
    "plot_test_scores(scores,y,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Classifier(0,best_hp,optimizer,op[0])\n",
    "classifier.load_weights('best_model_sgd.h5')\n",
    "predictions = classifier.predict(test_set)\n",
    "new_test_labels = np.zeros(test_labels.shape[0])\n",
    "for i in range(test_labels.shape[0]):\n",
    "    new_test_labels[i]=np.argmax(test_labels[i])\n",
    "y_pred = np.zeros(test_labels.shape[0])\n",
    "for i in range(test_labels.shape[0]):\n",
    "    y_pred[i]=np.argmax(predictions[i])\n",
    "plot_confusion_matrix(new_test_labels,y_pred,words_name,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on a random audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lines = sum(1 for line in open('testing_list.txt'))\n",
    "number = np.random.randint(num_lines)\n",
    "count = 0\n",
    "for line in open('testing_list.txt'):\n",
    "    if count==number:\n",
    "        audio = line\n",
    "    count+=1\n",
    "print (audio)\n",
    "fs, signal = wavfile.read('./audio_files/'+audio[0:-1])\n",
    "winsound.PlaySound('./audio_files/'+audio, winsound.SND_FILENAME)\n",
    "filter_bank,length=creation_filterbank(fs,signal)\n",
    "audio_signal=np.zeros((1,40,98,1))\n",
    "audio_signal[0,:,:,0]=filter_bank.T\n",
    "\n",
    "plot_output_NN(words_name,classifier,audio_signal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
